---
description: "Phase implementation report template for Sprint [NNN]: [Sprint Name]"
sprint: "[NNN-sprint-name]"
phase: "[N]"
user_story: "[USN]"
---

# Phase [N] Implementation Report: [Feature Name]

**Sprint**: [NNN-sprint-name]  
**User Story**: [USN] - [User Story Title]  
**Date**: [YYYY-MM-DD]  
**Status**: [üîÑ IN PROGRESS | ‚úÖ COMPLETE | ‚ö†Ô∏è BLOCKED | ‚ùå FAILED]

---

## Executive Summary

[2-3 sentence overview of what was implemented and its current state]

### Key Achievements

[Bulleted list of major accomplishments with status indicators (‚úÖ/‚ö†Ô∏è/‚ùå)]
- ‚úÖ **Achievement 1**: Description
- ‚úÖ **Achievement 2**: Description
- ‚ö†Ô∏è **Issue Identified**: Description
- ‚úÖ **Resolution Applied**: Description

---

## Implementation Details

### Test Suite (`tests/test_[feature].py`)

**Total Lines**: [N]  
**Test Classes**: [N]  
**Test Scenarios**: [N]  
**Pass Rate**: [N]/[N] ([N]%) [‚úÖ/‚ö†Ô∏è]

#### Test Coverage Table

| Test Class | Purpose | Status |
|------------|---------|--------|
| `TestFeature1` | What it tests | ‚úÖ PASS / ‚ö†Ô∏è FAIL |
| `TestFeature2` | What it tests | ‚úÖ PASS / ‚ö†Ô∏è FAIL |

**Test Results Summary**:
- ‚úÖ [Key test category 1]
- ‚úÖ [Key test category 2]
- ‚ö†Ô∏è [Issue if any]

#### Unit Tests (if applicable)

**Total Lines**: [N]  
**Test Classes**: [N]  
**Test Scenarios**: [N]  
**Pass Rate**: [N]/[N] ([N]%)

[Same table structure as above]

### Component Implementation (`source/[module]/[file].py`)

**Original Size**: [N] lines  
**Enhanced Size**: [N] lines  
**New Functions/Classes**: [N]

#### Implemented Components

1. **`component_name()`**
   - Purpose/responsibility
   - Key features
   - **Result**: ‚úÖ Functional / ‚ö†Ô∏è Partial / ‚ùå Failed

2. **`component_name_2()`**
   - Purpose/responsibility
   - Key features
   - **Result**: Status and verification

[Continue for all major components]

### Supporting Infrastructure

#### [Supporting Component 1] (`source/[path]/[file].py`)

**Added**: [What was added]

```python
# Key code snippet showing the addition
```

**Result**: ‚úÖ Status and how verified

[Repeat for other supporting components]

---

## Test Results

### [Test Category 1] Execution

```bash
pytest [test_files] -v [flags]
```

**Results**:
- ‚úÖ [N]/[N] tests PASSED ([N]% pass rate)
- ‚ö†Ô∏è [N] tests FAILED (if any - explain why)
- ‚è±Ô∏è Execution time: [N] seconds

### [Test Category 2] Execution (if applicable)

[Same structure]

### Combined Test Execution

```bash
pytest [all_relevant_tests] -v --cov=[modules] --cov-report=term-missing
```

**Results**:
- ‚úÖ [N] [category] tests PASSED
- ‚ö†Ô∏è [N] tests FAILED (if any)
- üìä Coverage: [N]% on `[module_path]`
- ‚è±Ô∏è Execution time: [N] seconds

---

## Failure Analysis

### Category 1: [Failure Type] ([N] tests) - [‚úÖ FIXED / ‚ö†Ô∏è PENDING / ‚ùå BLOCKED]

**Root Cause**: [Clear explanation of why tests failed or issue occurred]

**Example**:
```python
# Show the problematic code or test
```

**Solution Implemented** (if fixed):
- [What was done to fix it]
- [How it was verified]

**Impact**: [CRITICAL / HIGH / MEDIUM / LOW] - [Explanation]

**Time Taken**: ~[N] minutes (if fixed)

[Repeat for each failure category]

---

## Verification Against Requirements

### User Story [N] Requirements

| Requirement | Implementation | Verification |
|-------------|---------------|--------------|
| [Requirement 1] | `component_name()` | ‚úÖ Test name passes |
| [Requirement 2] | `component_name()` | ‚ö†Ô∏è Partial - missing [X] |
| [Requirement 3] | Implementation | ‚úÖ How verified |

**Functional Requirements**: [N]/[N] met [‚úÖ/‚ö†Ô∏è]  
**Critical Gap**: [None / Description of gap] [‚úÖ/‚ùå]

---

## Task Completion

### Phase [N] Tasks (T[NNN]-T[NNN])

| Task ID | Description | Status |
|---------|-------------|--------|
| T[NNN] | [Task description] | ‚úÖ Complete / ‚ö†Ô∏è Partial / ‚ùå Blocked |
| T[NNN] | [Task description] | Status |

**All tasks marked complete in tasks.md** ‚úÖ/‚ö†Ô∏è

---

## Key Technical Decisions

### 1. [Decision Name]

**Decision**: [What was decided]

**Rationale**: [Why this decision was made, what alternatives were considered]

**Impact**: [How this affected the implementation, performance, architecture, etc.]

### 2. [Decision Name]

[Same structure]

[Include 3-5 key technical decisions that shaped the implementation]

---

## Production Readiness Assessment

### ‚úÖ Production-Ready Features [All Complete / Partial]

- **Feature 1**: Description and verification
- **Feature 2**: Description and verification
- **Feature 3**: Description and verification

### ‚ö†Ô∏è Critical Requirements [Met / Pending / Blocked]

1. **[Requirement Name]** [‚úÖ/‚ö†Ô∏è/‚ùå]
   - **Severity**: CRITICAL / HIGH / MEDIUM / LOW
   - **Status**: COMPLETE / PENDING / BLOCKED
   - **Blocker**: YES / NO - explanation

[List all critical items that could block production]

### üîß Optional Improvements (Not Blocking)

3. **[Improvement Name]**
   - **Severity**: LOW
   - **Fix Effort**: ~[N] minutes
   - **Blocker**: NO - explanation
   - **Decision**: Deferred / Planned / Not needed

---

## Implementation Summary - [Option Name] [‚úÖ COMPLETE / ‚ö†Ô∏è PARTIAL]

### Option [N]: [Option Name] - [‚úÖ COMPLETED / ‚ö†Ô∏è PENDING / ‚ùå BLOCKED]

**Time Taken**: ~[N] minutes  
**Focus**: [What this option addressed]

**Tasks Completed**:
1. ‚úÖ **[Task 1]**
   - [What was done]
   - Verified: [How it was verified] ‚úÖ

2. ‚úÖ **[Task 2]**
   - [What was done]
   - Verified: [How it was verified] ‚úÖ

**Deliverable**: ‚úÖ [Summary of what was delivered]

[Include alternative options if applicable]

---

## Lessons Learned

[CRITICAL SECTION - This content will be extracted to central memory]

1. **[Lesson Title]**: [Detailed lesson learned with context, what went wrong/right, why it matters, and what to do differently next time. Be specific with examples and technical details.]

2. **[Lesson Title]**: [Same structure - each lesson should be actionable and transferable to future work]

3. **[Lesson Title]**: [Continue with 3-7 key lessons that would help future implementations]

[Examples of good lessons learned:
- Technical discoveries (e.g., "File Size Matters: Small test files (<1KB) exposed edge cases...")
- Process improvements (e.g., "TDD Catches Edge Cases Early: Writing tests first revealed...")
- Tool/framework insights (e.g., "Mock Patch Paths Are Fragile: Python's @patch decorator must patch...")
- Architecture decisions (e.g., "Integration Tests More Valuable Than Unit Tests: Integration tests with real...")
- Performance insights (e.g., "Error Classification Is Critical: Differentiating permanent vs transient errors...")
]

---

## Code Metrics

| Metric | Value |
|--------|-------|
| **Files Modified** | [N] ([list main files]) |
| **Files Created** | [N] ([list new files]) |
| **Lines of Code Added** | ~[N] lines |
| **Test Scenarios** | [N] comprehensive tests |
| **Test Success Rate** | [N]% ([N]/[N] passing) |
| **Coverage** | [N]% ([module coverage details]) |

---

## Appendix: Files Modified

### New Files

- `[path/to/file]` ([N] lines) - [Brief description]

### Modified Files

- `[path/to/file]` ([N] ‚Üí [N] lines, +[N] lines) - [What changed]

### Key Implementation Details

**[Feature Name]** (`[file_path]`):
```python
# Show key code snippets that are important for understanding
# the implementation or for future reference
```

**[Another Feature]** (`[file_path]`):
- Bullet points explaining the implementation if code snippet not needed

---

## Sign-Off

**Phase [N] Status**: [üîÑ IN PROGRESS / ‚úÖ COMPLETE / ‚ö†Ô∏è BLOCKED]  
**Integration Tests**: [‚úÖ/‚ö†Ô∏è] [N]/[N] PASSING ([N]%)  
**Unit Tests**: [‚úÖ/‚ö†Ô∏è] [N]/[N] PASSING ([N]%)  
**Functional Status**: [‚úÖ OPERATIONAL / ‚ö†Ô∏è PARTIAL / ‚ùå BLOCKED]  
**Production Ready**: [‚úÖ YES / ‚ö†Ô∏è WITH CAVEATS / ‚ùå NO]

**[Key Compliance Item]**: ‚úÖ/‚ö†Ô∏è/‚ùå [Status and details]  
**[Key Compliance Item]**: ‚úÖ/‚ö†Ô∏è/‚ùå [Status and details]  
**[Key Metric]**: [Value and interpretation]

**Deployment Clearance**: [‚úÖ APPROVED FOR PRODUCTION / ‚ö†Ô∏è CONDITIONAL / ‚ùå BLOCKED]

[Final assessment summary - 2-3 sentences on overall state and readiness]

**Next Phase**: [What comes next, if applicable]

---

*Report generated: [YYYY-MM-DD]*  
*Report updated: [YYYY-MM-DD] ([what changed])*  
*Sprint: [NNN-sprint-name]*  
*Phase: [N] of [N]*
